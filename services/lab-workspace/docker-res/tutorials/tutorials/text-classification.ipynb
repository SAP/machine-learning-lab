{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this notebook:**\n",
    "\n",
    "* Create sklearn classification model with tfidf vectorizer and LinearSVC classifier\n",
    "\n",
    "* This notebook is a demo notebook to show the ML Lab capabilities. Checkout the walkthrough section of the ML Lab documentation for more information of how to get the here described dataset etc.:\n",
    "    1. Create a project in ML Lab\n",
    "    2. Go to the Datasets view and upload the News Data\n",
    "    3. Go through this notebook and execute the cells to connect to an ML Lab instance, download the dataset to the workspace, create an experiment, and run it.\n",
    "    4. See the results of the experiments in the Experiments Dashboard of the web app\n",
    "    5. Upload the Unified Model to the ML Lab instance\n",
    "    6. One-click deploy the Unified Model via the web app\n",
    "    7. Access the service's API in the web app Services view and run an exemplary prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "Install, load, and initialize all required dependencies for this experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T18:45:12.799022Z",
     "start_time": "2018-02-26T18:45:12.784137Z"
    }
   },
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T12:06:45.774484Z",
     "start_time": "2020-08-24T12:06:43.714416Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# System libraries\n",
    "import logging, os, sys\n",
    "\n",
    "# Enable logging\n",
    "logging.basicConfig(format='[%(levelname)s] %(message)s', level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "# Intialize tqdm to always use the notebook progress bar\n",
    "import tqdm\n",
    "tqdm.tqdm = tqdm.tqdm_notebook\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ML Lab libraries\n",
    "from lab_client import Environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T12:07:06.996160Z",
     "start_time": "2020-08-24T12:07:05.484706Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize environment\n",
    "env = Environment(project=\"ml-lab-demo\"  # ML Lab project you want to work on. Must exist / be created in the ML Lab instance.\n",
    "                  # Only required in stand-alone workspace deployments:\n",
    "                  # lab_endpoint=\"LAB_ENDPOINT\", # ML Lab endpoint url: e.g. http://10.2.3.45:8091\n",
    "                  # lab_api_token=\"LAB_API_TOKEN\"\n",
    "                 ) \n",
    "\n",
    "# Initialize experiment\n",
    "exp = env.create_experiment('News Text Classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Download, explore, and prepare all required data for the experiment in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:51:47.022970Z",
     "start_time": "2020-08-19T13:51:46.570232Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get data from remote storage of ML Lab only if it does not exist locally\n",
    "dataset_path = env.get_file('datasets/news-categorized.csv')\n",
    "\n",
    "# Read data into basic pandas dataframe\n",
    "df = pd.read_csv(dataset_path, sep=\";\")\n",
    "\n",
    "# Configure dataset transfomration\n",
    "dataset_config = {\n",
    "    'train_size':0.80,\n",
    "    'min_label_count': 10\n",
    "}\n",
    "\n",
    "# Add dataset configuration to experiment parameters\n",
    "exp.log_params(dataset_config)\n",
    "\n",
    "# only use items with more than 10 labels\n",
    "df = df.groupby(\"label\").filter(lambda x: len(x) > dataset_config['min_label_count'])\n",
    "\n",
    "# Split the dataset into train (80%), and test (20%) based on dataset configuration\n",
    "train_df, test_df = np.split(df.sample(frac=1, random_state=2), [int(dataset_config['train_size']*len(df))])\n",
    "\n",
    "# add dataframes to experiment (will be logged and accesible within the experiment)\n",
    "exp.add_artifact(\"train_data\", train_df)\n",
    "exp.add_artifact(\"test_data\", test_df)\n",
    "\n",
    "# Show sample\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "Implementation, configuration, and evaluation of the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:51:52.983510Z",
     "start_time": "2020-08-19T13:51:49.966394Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Preprocessing logic\n",
    "def preprocess(data, **kwargs):\n",
    "    return str(data).replace('\\n', ' ').replace('\\r', '').strip().split()\n",
    "    \n",
    "# Training logic\n",
    "def train(exp, params, artifacts):\n",
    "    # exp (= Experiment instance)\n",
    "    # params (= parameter dictonary) \n",
    "    # artifacts (= dictionary of added artifacts)\n",
    "    \n",
    "    # Get artifacts for the experiment run\n",
    "    train_df = artifacts[\"train_data\"]\n",
    "    test_df = artifacts[\"test_data\"]\n",
    "    \n",
    "    # Experiment Implementation\n",
    "    classification_pipeline = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(analyzer=lambda x: x,min_df=params['min_df'])),\n",
    "        (\"lsvc_calib\", CalibratedClassifierCV(LinearSVC(verbose=0),method=\"isotonic\", cv=3))\n",
    "    ])\n",
    "    \n",
    "    sklearn_classifier = classification_pipeline.fit(\n",
    "        [preprocess(item) for item in train_df[\"text\"].tolist()], train_df[\"label\"].tolist()\n",
    "    )\n",
    "    \n",
    "    # Add trained model instance to experiment -> it can accessed after the exp-run is finished\n",
    "    exp.add_artifact(\"sklearn_classifier\", sklearn_classifier)\n",
    "    \n",
    "    # Evaluate trained model\n",
    "    score = sklearn_classifier.score(\n",
    "        [preprocess(item) for item in test_df[\"text\"].tolist()], test_df[\"label\"].tolist()\n",
    "    )\n",
    "    \n",
    "    # log a metric to the current experiment\n",
    "    exp.log_metric(\"accuracy\", score)\n",
    "    \n",
    "    print(\"Model trained. Accuracy: \" + str(score))\n",
    "    # optional: return the most descriptive metric (main objective) for the experiment\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:52:03.423110Z",
     "start_time": "2020-08-19T13:51:56.150065Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define parameter configuration for experiment run\n",
    "params = {\n",
    "    'min_df': 2\n",
    "}\n",
    "\n",
    "# Run experiment and sync all metadata\n",
    "exp.run_exp(train, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model\n",
    "Wrap the model with the Unified Model API and upload it to the remote storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Unified Model\n",
    "You can find information on how to create a self-contained executable model file in the [unified model library](https://github.com/SAP/machine-learning-lab/tree/master/libraries/unified-model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T14:18:04.335464Z",
     "start_time": "2020-08-19T14:17:38.329216Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create unified model instance here\n",
    "from unified_model.predefined_models.sklearn_models import SklearnTextClassifier\n",
    "\n",
    "# Optional: create a describable name for the model\n",
    "model_name = \"news-categorized_sklearn_classifier.model\"\n",
    "\n",
    "# Initialize unified model instance with trained model\n",
    "sklearn_model = SklearnTextClassifier(exp.get_artifact(\"sklearn_classifier\"), \n",
    "                                      transform_func=preprocess,\n",
    "                                      name=model_name)\n",
    "\n",
    "# Save the unified model within the dedicated experiment folder\n",
    "sklearn_model_path = sklearn_model.save(exp.create_file_path(model_name))\n",
    "\n",
    "# Evaluate unified model with test data\n",
    "metrics, label_scores = sklearn_model.evaluate(test_df['text'].tolist(), test_df['label'].tolist(), per_label=True)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Unified Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T14:18:07.509633Z",
     "start_time": "2020-08-19T14:18:04.340613Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env.upload_file(sklearn_model_path, data_type=\"model\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "840px",
    "width": "569px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
